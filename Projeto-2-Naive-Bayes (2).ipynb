{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Classificador Automático de Sentimento\n",
    "\n",
    "Você foi contratado por uma empresa parar analisar como os clientes estão reagindo a um determinado produto no Twitter. A empresa deseja que você crie um programa que irá analisar as mensagens disponíveis e classificará como \"relevante\" ou \"irrelevante\". Com isso ela deseja que mensagens negativas, que denigrem o nome do produto, ou que mereçam destaque, disparem um foco de atenção da área de marketing.<br /><br />\n",
    "Como aluno de Ciência dos Dados, você lembrou do Teorema de Bayes, mais especificamente do Classificador Naive-Bayes, que é largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser relevante dadas as palavras em seu conteúdo.<br /><br />\n",
    "Para realizar o MVP (*minimum viable product*) do projeto, você precisa implementar uma versão do classificador que \"aprende\" o que é relevante com uma base de treinamento e compara a performance dos resultados com uma base de testes.<br /><br />\n",
    "Após validado, o seu protótipo poderá também capturar e classificar automaticamente as mensagens da plataforma.\n",
    "\n",
    "## Informações do Projeto\n",
    "\n",
    "Prazo: 19/Set até às 23:59.<br />\n",
    "Grupo: 2 ou 3 pessoas - grupos com 3 pessoas terá uma rubrica diferenciada.<br /><br />\n",
    "Entregáveis via GitHub: \n",
    "* Arquivo notebook com o código do classificador, seguindo as orientações abaixo.\n",
    "* Arquivo Excel com as bases de treinamento e teste totalmente classificado.\n",
    "\n",
    "**NÃO gravar a key do professor no arquivo**\n",
    "\n",
    "\n",
    "### Entrega Intermediária: Check 1 - APS 2\n",
    "\n",
    "Até o dia 10/Set às 23:59, xlsx deve estar no Github com as seguintes evidências: \n",
    "\n",
    "  * Produto escolhido.\n",
    "  * Arquivo Excel contendo a base de treinamento e a base de testes já classificadas.\n",
    "\n",
    "Sugestão de leitura:<br />\n",
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Parte I - Adquirindo a Base de Dados\n",
    "\n",
    "Acessar o notebook **Projeto-2-Planilha** para realizar a coleta dos dados. O grupo deve classificar os dados coletados manualmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Parte II - Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. Não se esqueça de implementar o Laplace Smoothing (https://en.wikipedia.org/wiki/Laplace_smoothing).\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. Não remover emojis.<br />\n",
    "* Corrigir separação de espaços entre palavras e/ou emojis.\n",
    "* Propor outras limpezas/transformações que não afetem a qualidade da informação.\n",
    "\n",
    "Escreva o seu código abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Classificação</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>quero comer pão de coco c nescau</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt @tonystarkmeta: bolsonaro tomou uma facada ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@iam_mudblood ah se vao liberar nem esquenta l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28596 coisas pra estudar pra faculdade e pro t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt @gii_gcosta: fala uma verdade que niguem ac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Classificação\n",
       "0                   quero comer pão de coco c nescau              1\n",
       "1  rt @tonystarkmeta: bolsonaro tomou uma facada ...              0\n",
       "2  @iam_mudblood ah se vao liberar nem esquenta l...              0\n",
       "3  28596 coisas pra estudar pra faculdade e pro t...              0\n",
       "4  rt @gii_gcosta: fala uma verdade que niguem ac...              1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importanto o Banco de Dados\n",
    "data = pd.read_excel(\"tweets nescau classificação.xlsx\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Removendo caracteres irrelvantes.\n",
    "def limpador(batata):\n",
    "    batata0 = batata.str.replace(\"~\", \" \")\n",
    "    batata1 = batata0.str.replace(\"@\", \" \")\n",
    "    batata2 = batata1.str.replace(\":\",\" \")\n",
    "    batata3 = batata2.str.replace(\",\",\" \")\n",
    "    batata4 = batata3.str.replace(\".\",\" \")\n",
    "    batata5 = batata4.str.replace(\";\",\" \")\n",
    "    batata6 = batata5.str.replace(\"_\",\" \")\n",
    "    batata7 = batata6.str.replace(\"-\",\" \")\n",
    "    batata8 = batata7.str.replace(\"\\n\",\" \")\n",
    "    batata9 = batata8.str.replace(\" a \",\" \")\n",
    "    batata10 = batata9.str.replace(\" que \",\" \")\n",
    "    batata11 = batata10.str.replace(\" o \",\" \")\n",
    "    batata12 = batata11.str.replace(\"?\",\" \")\n",
    "    batata13 = batata12.str.replace(\"!\",\" \")\n",
    "    batata14 = batata13.str.replace(\"#\",\" \")\n",
    "    batata15 = batata14.str.replace(\"$\",\" \")\n",
    "    batata16 = batata15.str.replace(\"&\",\" \")\n",
    "    batata17 = batata16.str.replace(\"*\",\" \")\n",
    "    batata18 = batata17.str.replace(\" se \",\" \")\n",
    "    batata19 = batata18.str.replace(\"+\",\" \")\n",
    "    batata20 = batata19.str.replace(\"rt \",\" \")\n",
    "    batata21 = batata20.str.replace(\"=\",\" \")\n",
    "    batata22 = batata21.str.replace(\">\",\" \")\n",
    "    batata23 = batata22.str.replace(\"<\",\" \")\n",
    "    batata24 = batata23.str.replace(\"^\",\" \")\n",
    "    batata25 = batata24.str.replace(\"(\",\" \")\n",
    "    batata26 = batata25.str.replace(\")\",\" \")\n",
    "    batata27 = batata26.str.replace(\"2018\",\" \")\n",
    "    batata28 = batata27.str.replace(\"'\",\" \")\n",
    "\n",
    "\n",
    "# Transformando todas as palavras em minúsculas\n",
    "    batata29 = batata28.str.lower()\n",
    "\n",
    "#Removendo os espaços em branco e separando as palavras\n",
    "    batata30 = batata29.str.split()\n",
    "    return batata30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             [quero, comer, pão, de, coco, c, nescau]\n",
       "1    [tonystarkmeta, bolsonaro, tomou, uma, facada,...\n",
       "2    [iam, mudblood, ah, vao, liberar, nem, esquent...\n",
       "3    [28596, coisas, pra, estudar, pra, faculdade, ...\n",
       "4    [gii, gcosta, fala, uma, verdade, niguem, acei...\n",
       "Name: Treinamento, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removendo caracteres irrelvantes.\n",
    "\n",
    "limpador(data.Treinamento).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformando em DataFrame\n",
    "df_join = data.copy()\n",
    "df_join[\"Treinamento\"] = limpador(data[\"Treinamento\"])\n",
    "#df1 = pd.DataFrame(data=limpador(data.Treinamento))\n",
    "#df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformando em DataFrame\n",
    "#df2 = pd.DataFrame(data=data[\"Classificação\"])\n",
    "#df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Juntando ambos DataFrames em um único DataFrame mais limpo\n",
    "#df_join = df1.join(df2, how=\"inner\")\n",
    "#df_join.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Classificação</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[quero, comer, pão, de, coco, c, nescau]</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[tonystarkmeta, bolsonaro, tomou, uma, facada,...</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[iam, mudblood, ah, vao, liberar, nem, esquent...</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[28596, coisas, pra, estudar, pra, faculdade, ...</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[gii, gcosta, fala, uma, verdade, niguem, acei...</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento Classificação\n",
       "0           [quero, comer, pão, de, coco, c, nescau]     Relevante\n",
       "1  [tonystarkmeta, bolsonaro, tomou, uma, facada,...   Irrelevante\n",
       "2  [iam, mudblood, ah, vao, liberar, nem, esquent...   Irrelevante\n",
       "3  [28596, coisas, pra, estudar, pra, faculdade, ...   Irrelevante\n",
       "4  [gii, gcosta, fala, uma, verdade, niguem, acei...     Relevante"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Categorizando as classificações em Relevante( == 1) e Irrelevante( == 0)\n",
    "df_join.Classificação = df_join.Classificação.astype(\"category\")\n",
    "df_join.Classificação.cat.categories = (\"Irrelevante\", \"Relevante\")\n",
    "df_join.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Classificação</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[quero, comer, pão, de, coco, c, nescau]</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[gii, gcosta, fala, uma, verdade, niguem, acei...</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[bbhmymb, acabei, de, tomar, toddy, e, realmen...</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[fsox7, nãoconfioemgenteque, acha, toddy, é, m...</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[amo, nescau, deixar, bebo, toda, hora]</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento Classificação\n",
       "0           [quero, comer, pão, de, coco, c, nescau]     Relevante\n",
       "4  [gii, gcosta, fala, uma, verdade, niguem, acei...     Relevante\n",
       "5  [bbhmymb, acabei, de, tomar, toddy, e, realmen...     Relevante\n",
       "7  [fsox7, nãoconfioemgenteque, acha, toddy, é, m...     Relevante\n",
       "8            [amo, nescau, deixar, bebo, toda, hora]     Relevante"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separando os DataFrames de acordo com a Categoria\n",
    "\n",
    "df_relevante = df_join[df_join.Classificação==\"Relevante\"]\n",
    "df_irrelevante = df_join[df_join.Classificação==\"Irrelevante\"]\n",
    "\n",
    "df_relevante.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.33% de Tweets Relevantes\n",
      "49.67% de Tweets Irrelevantes\n"
     ]
    }
   ],
   "source": [
    "# Porcentagem de Tweets\n",
    "\n",
    "porcentagem_relevante = 100*(len(df_relevante) / len(df_join.Classificação))\n",
    "porcentagem_irrelevante = 100*(len(df_irrelevante) / len(df_join.Classificação))\n",
    "\n",
    "print(\"{:.2f}% de Tweets Relevantes\".format(porcentagem_relevante))\n",
    "print(\"{:.2f}% de Tweets Irrelevantes\".format(porcentagem_irrelevante))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Irrelevante'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def classificador_naive(frase):\n",
    "    \n",
    "    serie = pd.Series(frase)\n",
    "    serie_limpa = limpador(serie)\n",
    "    df_serie_limpa = pd.DataFrame(data=serie_limpa)\n",
    "    \n",
    "    probabilidade_relevante = 1\n",
    "    probabilidade_irrelevante = 1\n",
    "    \n",
    "    total_palavras=0\n",
    "    \n",
    "    for linha in df_join.Treinamento:\n",
    "        for palavra in linha:\n",
    "            total_palavras+=1\n",
    "    \n",
    "\n",
    "    for linha1 in df_serie_limpa[0]:\n",
    "        for palavra1 in linha1:\n",
    "            total_palavras_relevante = 0\n",
    "            conta_palavra1_relevante = 0\n",
    "\n",
    "            for linha in df_relevante.Treinamento:\n",
    "                for palavra2 in linha:\n",
    "                    total_palavras_relevante += 1\n",
    "                    if palavra1==palavra2:\n",
    "                        conta_palavra1_relevante += 1\n",
    "\n",
    "            probabilidade_palavra1_relevante = (conta_palavra1_relevante+1)/(total_palavras_relevante+total_palavras) #Laplace\n",
    "\n",
    "        probabilidade_relevante = probabilidade_relevante*probabilidade_palavra1_relevante\n",
    "    \n",
    "    for linha1 in df_serie_limpa[0]:\n",
    "        for palavra1 in linha1:\n",
    "            conta_palavra1_irrelevante = 0\n",
    "            total_palavras_irrelevante = 0\n",
    "            \n",
    "            for linha in df_irrelevante.Treinamento:\n",
    "                for palavra2 in linha:\n",
    "                    total_palavras_irrelevante += 1\n",
    "                    if palavra1==palavra2:\n",
    "                        conta_palavra1_irrelevante += 1\n",
    "\n",
    "            probabilidade_palavra1_irrelevante = (conta_palavra1_irrelevante+1)/(total_palavras_irrelevante+total_palavras) #Laplace\n",
    "\n",
    "        probabilidade_irrelevante = probabilidade_irrelevante*probabilidade_palavra1_irrelevante\n",
    "\n",
    "    if probabilidade_relevante>probabilidade_irrelevante:\n",
    "        return(\"Relevante\")\n",
    "    else:\n",
    "        return(\"Irrelevante\")\n",
    "\n",
    "classificador_naive( \"para limpar bom é bolsonaro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu Classificador com a base de Testes.<br /><br /> \n",
    "\n",
    "Você deve extrair as seguintes medidas:\n",
    "* Porcentagem de positivos falsos (marcados como relevante mas não são relevantes)\n",
    "* Porcentagem de positivos verdadeiros (marcado como relevante e são relevantes)\n",
    "* Porcentagem de negativos verdadeiros (marcado como não relevante e não são relevantes)\n",
    "* Porcentagem de negativos falsos (marcado como não relevante e são relevantes)\n",
    "\n",
    "Obrigatório para grupos de 3 alunos:\n",
    "* Criar categorias intermediárias de relevância baseado na diferença de probabilidades. Exemplo: muito relevante, relevante, neutro, irrelevante e muito irrelevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidade de positivos falsos: 7.5%\n",
      "Probabilidade de positivos verdadeiros: 53.0%\n",
      "Probabilidade de negativos falsos: 18.0%\n",
      "Probabilidade de negativos verdadeiros: 21.5%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('74.5% de acerto', '25.5% de erro')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def verificador_total(data):\n",
    "    \n",
    "    base_teste = pd.read_excel(data)\n",
    "    \n",
    "    df_teste = pd.DataFrame(data=base_teste)\n",
    "    \n",
    "    df_teste.Classificação = df_teste.Classificação.astype(\"category\")\n",
    "    df_teste.Classificação.cat.categories = (\"Irrelevante\", \"Relevante\")\n",
    "    \n",
    "    total_certo=0\n",
    "    total_errado=0\n",
    "    total=0\n",
    "    \n",
    "    positivos_falsos=0\n",
    "    positivos_verdadeiros=0\n",
    "    negativos_verdadeiros=0\n",
    "    negativos_falsos=0\n",
    "    \n",
    "    i=0\n",
    "    \n",
    "    while i <len(df_teste):\n",
    "        resultado=classificador_naive(df_teste[\"Teste\"][i])\n",
    "        \n",
    "        if resultado==df_teste[\"Classificação\"][i]:\n",
    "            #print(\"acertou\")\n",
    "            if resultado==\"Relevante\":\n",
    "                positivos_verdadeiros+=1 #Relevante e acertou\n",
    "            else:\n",
    "                negativos_verdadeiros+=1 #Irrelevante e acertou\n",
    "            total_certo+=1\n",
    "        else:\n",
    "            #print(\"errou\")\n",
    "            if resultado==\"Irrelevante\":\n",
    "                positivos_falsos+=1 #Relevante e errou\n",
    "            else:\n",
    "                negativos_falsos+=1 #Irrelevante e errou\n",
    "            total_errado+=1\n",
    "            \n",
    "        total+=1\n",
    "        \n",
    "        i+=1\n",
    "        \n",
    "    probabilidade_certo=(total_certo/total)*100\n",
    "    probabilidade_errado=100*total_errado/total\n",
    "    \n",
    "    prob_positivos_falsos=100*positivos_falsos/total\n",
    "    prob_positivos_verdadeiros=100*positivos_verdadeiros/total\n",
    "    prob_negativos_falsos=100*negativos_falsos/total\n",
    "    prob_negativos_verdadeiros=100*negativos_verdadeiros/total\n",
    "    \n",
    "    print(\"Probabilidade de positivos falsos: {}%\".format(prob_positivos_falsos))\n",
    "    print(\"Probabilidade de positivos verdadeiros: {}%\".format(prob_positivos_verdadeiros))\n",
    "    print(\"Probabilidade de negativos falsos: {}%\".format(prob_negativos_falsos))\n",
    "    print(\"Probabilidade de negativos verdadeiros: {}%\".format(prob_negativos_verdadeiros))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return (\"{}% de acerto\".format(probabilidade_certo), \"{}% de erro\".format(probabilidade_errado))\n",
    "    \n",
    "    \n",
    "verificador_total(\"tweets nescau classificação verificação.xlsx\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Concluindo\n",
    "\n",
    "Escreva aqui a sua conclusão.<br /> \n",
    "Faça um comparativo qualitativo sobre as medidas obtidas.<br />\n",
    "Explique como são tratadas as mensagens com dupla negação e sarcasmo.<br />\n",
    "Proponha um plano de expansão. Por que eles devem continuar financiando o seu projeto?<br />\n",
    "\n",
    "Opcionalmente: \n",
    "* Discorrer por que não posso alimentar minha base de Treinamento automaticamente usando o próprio classificador, aplicado a novos tweets.\n",
    "* Propor diferentes cenários de uso para o classificador Naive-Bayes. Cenários sem intersecção com este projeto.\n",
    "* Sugerir e explicar melhorias reais no classificador com indicações concretas de como implementar (não é preciso codificar, mas indicar como fazer e material de pesquisa sobre o assunto).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.5% dos tweets foram classificados como relevantes na base teste\n",
      "39.5% dos tweets foram classificados como irrrelevantes na base teste\n"
     ]
    }
   ],
   "source": [
    "base_teste = pd.read_excel(\"tweets nescau classificação verificação.xlsx\")\n",
    "\n",
    "total=0\n",
    "total_classificado_como_relevante=0\n",
    "total_classificado_como_irrelevante=0\n",
    "\n",
    "for i in base_teste.Classificação:\n",
    "    total+=1\n",
    "    if i==1:\n",
    "        total_classificado_como_relevante+=1\n",
    "    else:\n",
    "        total_classificado_como_irrelevante+=1\n",
    "        \n",
    "pcntg_relevante=100*total_classificado_como_relevante/total\n",
    "pcntg_irrelevante=100*total_classificado_como_irrelevante/total\n",
    "\n",
    "print(\"{}% dos tweets foram classificados como relevantes na base teste\".format(pcntg_relevante))\n",
    "print(\"{}% dos tweets foram classificados como irrrelevantes na base teste\".format(pcntg_irrelevante))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Cada vez mais, empresas necessitam de informações para avaliar o seu rendimento. Com isso, a busca por dados e postagens são algo de extremo interesse no mundo corporativo. Tendo isso em vista, as redes sociais desempenham um papel ideal de divulgação de informações, através de postagens de seus usuários, bastante relevantes para grandes corporações. Com o intuito de captar informações relevantes para empresas, foi criado um algoritmo que digere os dados, retornando apenas aqueles que possuem conteúdo significativo para a empresa. Assim, com o código acima, é possível simular um exemplo de Machine Learning, algo utilizado em grande escala, por empresas mundo a fora, para lidar com uma enorme quantidade de dados. Como funciona: inserimos uma série de conteúdos diversos no computador, e apartir desses conteúdos adicionados (servem como exemplo sobre o que é relevante e o que é irrelevante) o computador \"aprende\" a executar a tarefa de filtrar apenas conteúdo relevante para uma empresa. Tendo em vista a automação como fator diferencial no mercado, é possível expandir esse código de modo que este possa ser ainda mais preciso. Visando obter o melhor rendimento possível e conquistar a clientela, ganhando mais espaço no mercado, é imprescindível que investimentos sejam feitos nesse setor. \n",
    "  \n",
    "  No modelo acima, foi utilizado tweets relacionados ao produto Nescau como exemplo. A partir dos resultados fornecidos pelo algoritmo podemos constatar que: na base teste 60.5% dos tweets que classificamos manualmente foram designados como relevantes, se simplesmente nossa função classificasse todos os tweets como relevantes teríamos como probabilidade de acerto de nosso classificador naive 60.5%. Contudo, como o objetivo é retornar o conteúdo relevante de maneira autônoma, o algoritmo foi implementado e obteve um graude de acerto de 74.5%. Isso mostra que usando o teorema de bayes conseguimos classificar corretamente 74.5% de tweets publicados por um público aleatório. Isso nos diz que a cada 4 tweets, 3 são classificados corretamente, um resultado incrível para um código que exerce uma função de maneira autônoma sem o auxílio de um ser humano. Além do código fornecer se o tweet é irrelevante ou relevante, também é retornado a porcentagem de tweets relevantes classificados corretamente e incorretamente, e a quantidade de tweets irrelevantes classificados erroneamente e de maneira correta.\n",
    "   \n",
    "   Uma das maneiras de melhorar o grau de acerto da nossa função, é colocando as probabilidades numa escala logarítmica que trataria com maior precisão as probabilidades dos tweets serem ou não relevantes. Traduzir as abreviações para seus respectivos significados, traduzir o significado de um emoji com relevante ou irrelevante, e buscar outras informações e postagens, que possam ser relevantes, dos usuários são algumas melhoras que podem acarretar em uma maior precisão do código para empresas.\n",
    "   \n",
    "   As mensagens de duplo sentido acabam por ser tratadas como irrelevantes, visto que o código não consegue destinguir através das palavras. Com isso, para que essas mensagens possam ser avaliadas de maneira correta, é necessário uma maior interpretação da frase, analisando o sentido de emojis publicados (se houverem alguns), analisar algumas \"#\" adicionadas e também outros tweets do mesmo usuário.\n",
    "   \n",
    "   Não podemos alimentar a base de Treinamento utilizando o próprio classificador, visto que trata-se de um exemplo de Machine Learning. A máquina \"aprende\" o que é relevante e irrelevante a partir de uma série de exemplos já classificados. Assim, através do calculo de probabilidades desses exemplos contendo inúmeras palavras, é possível determinar se uma frase é relevante ou não. Portanto, precisamos de um banco de dados classificados por um humano, que sirvam como exemplo para o código exercer sua função de maneira correta. Desse modo, não podemos utilizar o código nesse banco de dados, visto que dará um resultado 100% correto, algo que não será repetido para outros bancos de dados.\n",
    "   \n",
    "   Diferentes cenários para a utilização do Naive-Baies são: na medicina para diagonsticar uma pesso através de imagens, que possam apontar indícios de uma doença. Calcula-se a probabilidade de certa característica específica na imagem ser ou não um sinal, a partir de diversas amostras já classificadas, e apartir delas decidir se a imagem analisada possui ou não indícios de uma doença; no universo dos esportes, para calcular quais são as melhores condições para a realização do esporte, e obtenção dos melhores resultados. Isso é calculado através de informações prévias já fornecidas, por atletas que as obteram através experiências empíricas. Com essas informações é possível calcular se uma determinada condição será positiva ou negativa para a realização do esporte, ou se aquela condição influenciará de modo a acarretar resultados melhores ou piores do que a média. Além desses dois exemplos, uma última aplicação seria no Mercado Financeiro de modo a prever se a bolsa de valores terá uma tendência a melhorar ou não. Através de resultados anteriores, é possível prever se uma certa ação terá seu preço ascendente ou descendente em meio a uma sequência de ações que foram registradas e absorvidas pela máquina. Assim pode ser calculado a probabilidade da ação subir, de modo a maximizar os investimentos de um trader. \n",
    "   \n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
